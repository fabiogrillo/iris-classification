{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c14949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/Projects/MachineLearning/Sentiment-Analysis-NLP/venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee88ff121d8149fc972d1563cad9e1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020baa15af6b4fee8ec42073107de724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4085' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4085/4689 10:31 < 01:33, 6.47 it/s, Epoch 2.61/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>0.260420</td>\n",
       "      <td>0.901360</td>\n",
       "      <td>0.894696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.217620</td>\n",
       "      <td>0.929240</td>\n",
       "      <td>0.929654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "mlflow.set_experiment(\"Sentiment Analysis Transformers\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Load training and testing data\n",
    "train_df = pd.read_csv(\"../data/processed/train_clean.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/test_clean.csv\")\n",
    "\n",
    "# Prepare Dataset (include text_clean column for tokenization)\n",
    "train_dataset = Dataset.from_pandas(train_df[['text_clean', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['text_clean', 'label']])\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text_clean'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/distilbert\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1_metric.compute(predictions=preds, references=labels)[\"f1\"],\n",
    "    }\n",
    "\n",
    "# Train with MLflow\n",
    "with mlflow.start_run(run_name=\"distilbert-finetuned\"):\n",
    "    mlflow.log_param(\"model\", model_name)\n",
    "    mlflow.log_param(\"epochs\", training_args.num_train_epochs)\n",
    "    mlflow.log_param(\"batch_size\", training_args.per_device_train_batch_size)\n",
    "    mlflow.log_param(\"learning_rate\", training_args.learning_rate)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate and log metrics\n",
    "    eval_results = trainer.evaluate()\n",
    "    mlflow.log_metrics(eval_results)\n",
    "\n",
    "    # Save the model\n",
    "    trainer.save_model(\"../models/distilbert-final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7266b66",
   "metadata": {},
   "source": [
    "# Fine-tuning DistilBERT for Sentiment Analysis\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "```\n",
    "Raw Text                    Tokenization                  DistilBERT Encoder              Classification\n",
    "    │                            │                              │                              │\n",
    "    ▼                            ▼                              ▼                              ▼\n",
    "\"I loved this movie\"  →  [101, 1045, 2439, ...]  →  [768-dim embeddings]  →  Linear(768→2)  →  [pos/neg]\n",
    "                              │                              │                              │\n",
    "                         WordPiece                    Self-Attention               Softmax\n",
    "                         + Padding                    (6 layers)                   Probabilities\n",
    "```\n",
    "\n",
    "**Key steps:**\n",
    "1. **Tokenize** text into subword tokens (WordPiece) with special tokens `[CLS]` and `[SEP]`\n",
    "2. **Encode** through 6 transformer layers with self-attention (each token attends to all others)\n",
    "3. **Classify** using the `[CLS]` token representation through a linear layer\n",
    "\n",
    "## Training Results\n",
    "\n",
    "| Epoch | Training Loss | Validation Loss | Accuracy | F1 |\n",
    "|-------|---------------|-----------------|----------|-----|\n",
    "| 1 | 0.2498 | 0.3120 | 87.91% | 0.866 |\n",
    "| 2 | 0.1451 | 0.2151 | 92.39% | 0.923 |\n",
    "| 3 | 0.0658 | 0.3182 | **92.74%** | **0.927** |\n",
    "\n",
    "**Note:** Validation loss increased at epoch 3 while accuracy improved slightly — early sign of overfitting.\n",
    "\n",
    "## Model Comparison\n",
    "\n",
    "| Model | Accuracy | F1 | Improvement |\n",
    "|-------|----------|-----|-------------|\n",
    "| TF-IDF + LogReg | 89.2% | 0.89 | baseline |\n",
    "| Word2Vec + BiLSTM | 85.1% | 0.85 | -4.1% |\n",
    "| **DistilBERT** | **92.7%** | **0.93** | **+3.5%** |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Inference**: Test the model on custom movie reviews\n",
    "2. **MLOps**: Register model in MLflow Model Registry\n",
    "3. **Deployment**: Create FastAPI endpoint for real-time predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.argmax(axis=-1)\n",
    "y_true = test_df['label'].values\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(f'DistilBERT Confusion Matrix - Accuracy: {(y_pred == y_true).mean():.2%}')\n",
    "plt.savefig(\"../figures/confusion_matrix_distilbert.png\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5289be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load model saved\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"../models/distilbert-final\",\n",
    "    tokenizer=\"distilbert-base-uncased\"\n",
    ")\n",
    "\n",
    "# Test on custom review\n",
    "test_reviews = [\n",
    "    \"This movie was asthonishingly good! The plot was thrilling and the characters were well-developed.\",\n",
    "    \"Boring plot and terrible acting. I wouldn't recommend this film to anyone.\",\n",
    "    \"The cinematography was beautiful, but the story was lacking depth and originality.\",\n",
    "    \"I slept through half of it.\",\n",
    "    \"An absolute masterpiece! A must-watch for everyone. Even if you're not a fan of the genre.\"\n",
    "]\n",
    "\n",
    "# Predictions\n",
    "print(\"=\" * 60)\n",
    "print(\"INFERENCE ON CUSTOM REVIEWS\")\n",
    "print(\"=\" * 60)\n",
    "for review in test_reviews:\n",
    "    result = classifier(review)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    sentiment = \"Positive\" if label == \"LABEL_1\" else \"Negative\"\n",
    "    print(f\"\\nReview: {review[:50]}...\")\n",
    "    print(f\"Predicted sentiment: {sentiment} (confidence: {score:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9306a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Comparison\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"TF-IDF + LogReg\", \"Word2Vec + BiLSTM\", \"DistilBERT Transformer\"],\n",
    "    \"Accuracy\": [0.892, 0.851, 0.927],\n",
    "    \"F1 Score\": [0.890, 0.85, 0.93],\n",
    "    \"Training Time\": ['~30s', '~5m', '~20m'],\n",
    "    \"Inference Speed\": ['Fast', 'Medium', 'Slow'],\n",
    "    \"GPU Required\": ['No', 'Yes', 'Yes']\n",
    "})\n",
    "\n",
    "print(results_df.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
